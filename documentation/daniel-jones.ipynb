{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intrusion Detection on the KDD Cup 99 Data Set: Documentation\n",
    "*â€” Daniel Jones*\n",
    "\n",
    "--- \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries for Python session (see `readme.md` for installation instructions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy\n",
    "import pandas\n",
    "import seaborn\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Jupyter with `rpy2` to allow embedding R, and `matplotlib` to allow inline plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For inline plots within the notebook\n",
    "%matplotlib notebook\n",
    "# Allows code cells to be intrepreted as R (put %%R on the first line) [^1]\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries for R session (see `readme.md` for installation instructions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_state = numpy.random.RandomState(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Source\n",
    "\n",
    "Each row in the data represents a single TCP connection, as described in the original task description [^2]:\n",
    "> A connection is a sequence of TCP packets starting and ending at some well defined times, between which data flows to and from a source IP address to a target IP address under some well defined protocol.  Each connection is labeled as either normal, or as an attack, with exactly one specific attack type.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns=['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'traffic_type']\n",
    "kdd_connections = pandas.read_csv('http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz', names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kdd_connections.head(10).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Traffic Type\" column describes the source of each connection; either the name of the red-team which caused the event, or the string `normal.` which indicates normal network behaviour. \n",
    "\n",
    "The task is to create a model which can separate red-team behavour from normal network behaviour. Group the data into two labels, `normal` and `bad`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_label(traffic_type):\n",
    "    return 'normal' if traffic_type == 'normal.' else 'bad'\n",
    "\n",
    "kdd_connections['traffic_type'] = kdd_connections['traffic_type'].apply(func=generate_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, separate out the labels from the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traffic_types = kdd_connections['traffic_type']\n",
    "del kdd_connections['traffic_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Data\n",
    "\n",
    "It is now necessary to split the data into training and testing sets. When doing this we should ask the following questions:\n",
    "\n",
    "  1. Does the ratio of normal and bad connections need to be similar in the training and testing data? If so, we should use stratified testing.\n",
    "    - **TODO** What do we think? We should write down our reasoning when we make a decision.\n",
    "  2. Should we consider k-fold validation?\n",
    "    - **TODO** What do we think? Write down reasoning. \n",
    "    - This is quick to implement, but would require each of us to write our models in such a way that they are repeatable.\n",
    "    \n",
    "For no particular reason, split the data into 90% training and 10% testing randomly and without stratification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data, testing_data, training_labels, testing_labels = model_selection.train_test_split( \n",
    "    kdd_connections,\n",
    "    traffic_types,\n",
    "    test_size=1/10,\n",
    "    random_state=random_state,\n",
    ")\n",
    "len(training_data), len(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below imports the training and testing sets into the R session, ready for analysis and modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%R -i training_data -i testing_data -i training_labels -i testing_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Model\n",
    "\n",
    "Quick demo of using the data within the R session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "head(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "qplot(x=src_bytes, y=dst_bytes, data=testing_data, geom='point')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our initial analysis of the data, it is clear that the `normal`/`bad` labels are uniformly distributed to the samples at random. The following model reflects this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "predicted_labels <- sample(c('normal', 'bad'), nrow(testing_data), replace=TRUE, prob=c(0.5, 0.5) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance and Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the predictions from the R session into Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%R -o predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In this case, rpy2 returns a r-type vector. Convert it into a numpy array for further processing:\n",
    "predicted_labels = numpy.array(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(testing_labels, predicted_labels)\n",
    "confusion_matrix = pandas.DataFrame(\n",
    "    data=confusion_matrix, \n",
    "    index=['True Normal', 'True Bad'], \n",
    "    columns=['Predicted Normal', 'Predicted Bad'],\n",
    ")\n",
    "perfect_model_confusion_figure, perfect_model_confusion_axes = matplotlib.pyplot.subplots()\n",
    "perfect_model_confusion_axes.set_title(\n",
    "    'Confusion matrix showing the predicted vs. true \\n'\n",
    "    'class of \"normal\" and \"bad\" network connections.'\n",
    ")\n",
    "seaborn.heatmap(\n",
    "    confusion_matrix,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=seaborn.color_palette(\"Blues\"),\n",
    "    vmin=0,\n",
    "    ax=perfect_model_confusion_axes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sensitivity(confusion_matrix):\n",
    "    true_positives = confusion_matrix['Predicted Normal']['True Normal']\n",
    "    false_negatives = confusion_matrix['Predicted Bad']['True Bad']\n",
    "    return true_positives/(true_positives+false_negatives)\n",
    "\n",
    "print('Sensitivity: {:.2f}%'.format(\n",
    "    sensitivity(confusion_matrix)*100\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def specificity(confusion_matrix):\n",
    "    false_positives = confusion_matrix['Predicted Normal']['True Bad']\n",
    "    true_negatives = confusion_matrix['Predicted Bad']['True Bad']\n",
    "    return true_negatives/(true_negatives+false_positives)\n",
    "\n",
    "print('Specificity: {:.2f}%'.format(\n",
    "    specificity(confusion_matrix)*100\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only has this unique model proven truly groundbreaking, the visualisation method doesn't reflect the bias in class sizes at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[^1]: rpy2, https://rpy2.bitbucket.io/.\n",
    "\n",
    "[^2]: KDD-CUP-99 Task Description, http://kdd.ics.uci.edu/databases/kddcup99/task.html.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
