{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intrusion Detection on the KDD Cup 99 Data Set\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup\n",
    "\n",
    "This notebook has been setup to allow both Python and R to work together. For it to work, make sure you have the correct Python and R environments setup (see [./README.md](./README.md)). \n",
    "\n",
    "By default all code cells are in Python. To use R, start a code cell with the line `%%R` to tell the notebook to interpret the whole cell as R code. This is setup in such a way that it is effectively two notebooks intertwined; one in R and one in Python. Special code cells can then be used to ferry data between the two notebooks:\n",
    "  - `%Rpush <variable_name>` will copy a piece of data from the Python notebook to the R notebook\n",
    "  - `%Rpull <variable_name>` will copy a piece of data from the R notebook to the Python notebook\n",
    "  \n",
    "More `<variable_name>`s can be appended to the above lines (with space separators), e.g: `%Rpull foo bar` will copy the `foo` and `bar` variables from R to Python. This should work ok in general provided we stick to using data frames when communicating between the two notebooks (other types tend to require some massaging on the either end)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib  # graphs and plotting for python\n",
    "import numpy  # fast arrays for python (used by pandas)\n",
    "import pandas  # provides dataframe's and similar structures for python\n",
    "import seaborn  # provides pre-configured, pretty graphs for matplotlib\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Jupyter with `rpy2` to allow embedding R, and `matplotlib` to allow inline plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For inline plots within the notebook\n",
    "%matplotlib notebook\n",
    "# Allows code cells to be intrepreted as R (put %%R on the first line) [^1]\n",
    "%load_ext rpy2.ipython\n",
    "# Render R output as HTML\n",
    "from rpy2.ipython import html\n",
    "html.init_printing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(caret)\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_state = numpy.random.RandomState(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns=['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'connection_label']\n",
    "connection_events = pandas.read_csv('http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz', names=columns)  # [^3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "connection_events.head(10).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `connection_label` column describes the source of each connection; either the name of the red-team which caused the event, or the string `normal.` which indicates normal network behaviour. \n",
    "\n",
    "The task is to create a model which can separate red-team behavour from normal network behaviour, so group the data into two labels: `normal` and `bad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_label(connection_label):\n",
    "    return 'normal' if connection_label == 'normal.' else 'bad'\n",
    "\n",
    "connection_events['connection_label'] = connection_events['connection_label'].apply(func=generate_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, separate out the labels from the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connection_labels = connection_events.filter(['connection_label'], axis='columns')\n",
    "connection_events = connection_events.drop(['connection_label'], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Data\n",
    "\n",
    "It is now necessary to split the data into training and testing sets. The code below performs 10-fold cross-validation, providing the array `train_test_splits`. It does this using the [model selection](http://scikit-learn.org/stable/modules/cross_validation.html#stratified-k-fold) part of the scikit-learn library [^5]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_fold_splitter = model_selection.StratifiedKFold(n_splits=10,  random_state=random_state)\n",
    "train_test_splits = k_fold_splitter.split(\n",
    "    connection_events,  # data to be split\n",
    "    connection_labels,  # target/class to split by\n",
    ")\n",
    "\n",
    "# Force evaluation of the train_test_splits generator into a list. This needs to be\n",
    "# done before it's sent to R.\n",
    "train_test_splits = [\n",
    "    [training_indexes, testing_indexes]\n",
    "    for training_indexes, testing_indexes in train_test_splits\n",
    "]\n",
    "\n",
    "# Here train_test_splits is a list, where each item represents a single 90/10 split of \n",
    "# training and testing data respectively:\n",
    "#\n",
    "#   train_test_splits = [\n",
    "#      (indexes_of_training_samples, indexes_of_test_samples),  # first split\n",
    "#      (indexes_of_training_samples, indexes_of_test_samples),  # second split\n",
    "#      ...\n",
    "#      (indexes_of_training_samples, indexes_of_test_samples),  # kth split\n",
    "#  ]\n",
    "#\n",
    "# These indexes can then be used to fetch the data samples and their labels,\n",
    "# ready for training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below imports the connection data, it's labels and the train/test splits into the R session, ready for analysis and modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%Rpush train_test_splits connection_events connection_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are helper functions which will extract the training (or test) data from a data frame, given an item of the `train_test_splits` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "get_training_rows <- function(dataframe, train_test_split) {\n",
    "    # Training indexes are the first item in a train_test_split\n",
    "    indexes <- train_test_split[[1]]\n",
    "    \n",
    "    # Python indices start at 0, whilst R indices start at 1.\n",
    "    # Correct for this by incrementing each index by 1:\n",
    "    indexes <- indexes + 1\n",
    "    \n",
    "    dataframe[indexes,]\n",
    "}\n",
    "\n",
    "get_testing_rows <- function(dataframe, train_test_split) {\n",
    "    # Testing indexes are the second item in a train_test_split\n",
    "    indexes <- train_test_split[[2]]\n",
    "    \n",
    "    # Python indices start at 0, whilst R indices start at 1.\n",
    "    # Correct for this by incrementing each index by 1:\n",
    "    indexes <- indexes + 1  \n",
    "    \n",
    "    dataframe[indexes,]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example showing how to extract the first set of training and testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# Use the indexes to get out the training data\n",
    "training_data <- get_training_rows(connection_events, train_test_splits[[1]])\n",
    "training_labels <- get_training_rows(connection_labels, train_test_splits[[1]])\n",
    "# These data frames can then be used to train your model.\n",
    "\n",
    "# Use the indexes to get out the testing data\n",
    "testing_data <- get_testing_rows(connection_events, train_test_splits[[1]])\n",
    "testing_labels <- get_testing_rows(connection_labels, train_test_splits[[1]])\n",
    "# Run the model on testing data, and consider how well the classification compares to their true values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Model\n",
    "\n",
    "Here's a quick demo showing how to use the data within the R notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "summary(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "qplot(x=src_bytes, y=dst_bytes, data=testing_data, geom='point')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, we would want to do the folllowing for each train/test split $i$ :\n",
    "  1. Train the model based on the $i$-th set of training data and labels.\n",
    "  2. Apply this trained model on the $i$-th set of testing data.\n",
    "  3. Save the set of predicted labels.\n",
    "  \n",
    "Then return a vector of each of these sets of predicted labels.\n",
    "\n",
    "For this example, come up with a silly set of predicted labels for each of our 10 training/testing splits. This is the format of predicted labels expected by the performance analsysi in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "predicted_label_sets <- list(\n",
    "    sample(c('normal', 'bad'), nrow(train_test_splits[[1]][[2]]), replace=TRUE, prob=c(0.5, 0.5)),\n",
    "    sample(c('normal', 'bad'), nrow(train_test_splits[[2]][[2]]), replace=TRUE, prob=c(0.5, 0.5)),\n",
    "    sample(c('normal', 'bad'), nrow(train_test_splits[[3]][[2]]), replace=TRUE, prob=c(0.5, 0.5)),\n",
    "    sample(c('normal', 'bad'), nrow(train_test_splits[[4]][[2]]), replace=TRUE, prob=c(0.5, 0.5)),\n",
    "    sample(c('normal', 'bad'), nrow(train_test_splits[[5]][[2]]), replace=TRUE, prob=c(0.5, 0.5)),\n",
    "    sample(c('normal', 'bad'), nrow(train_test_splits[[6]][[2]]), replace=TRUE, prob=c(0.5, 0.5)),\n",
    "    sample(c('normal', 'bad'), nrow(train_test_splits[[7]][[2]]), replace=TRUE, prob=c(0.5, 0.5)),\n",
    "    sample(c('normal', 'bad'), nrow(train_test_splits[[8]][[2]]), replace=TRUE, prob=c(0.5, 0.5)),\n",
    "    sample(c('normal', 'bad'), nrow(train_test_splits[[9]][[2]]), replace=TRUE, prob=c(0.5, 0.5)),\n",
    "    sample(c('normal', 'bad'), nrow(train_test_splits[[10]][[2]]), replace=TRUE, prob=c(0.5, 0.5))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance and Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the predictions from the R session into Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%Rpull predicted_label_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rpy2 returns an r-type list of character vectors. Convert each set of predictions into a numpy \n",
    "# array for processing with numpy/pandas/sklearn etc.\n",
    "predicted_label_sets = [numpy.array(predicted_labels) for predicted_labels in predicted_label_sets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance analysis could be done in R or Python. Here is an example in Python [^4]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "true_label_sets = [connection_labels.iloc[testing_indexes] for training_indexes, testing_indexes in train_test_splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusion_matrixes = [\n",
    "    metrics.confusion_matrix(true_labels, predicted_labels)\n",
    "    for true_labels, predicted_labels\n",
    "    in zip(true_label_sets, predicted_label_sets)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary_confusion_matrix = sum(confusion_matrixes)\n",
    "summary_confusion_matrix = pandas.DataFrame(\n",
    "    data=summary_confusion_matrix, \n",
    "    index=['True Normal', 'True Bad'], \n",
    "    columns=['Predicted Normal', 'Predicted Bad'],\n",
    ")\n",
    "\n",
    "summary_confusion_figure, summary_confusion_axes = matplotlib.pyplot.subplots()\n",
    "summary_confusion_axes.set_title(\n",
    "    'Confusion matrix showing the predicted vs. true \\n'\n",
    "    'class of \"normal\" and \"bad\" network connections.'\n",
    ")\n",
    "seaborn.heatmap(\n",
    "    summary_confusion_matrix,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=seaborn.color_palette(\"Blues\"),\n",
    "    vmin=0,\n",
    "    ax=summary_confusion_axes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sensitivity(confusion_matrix):\n",
    "    true_positives = confusion_matrix['Predicted Normal']['True Normal']\n",
    "    false_negatives = confusion_matrix['Predicted Bad']['True Normal']\n",
    "    return true_positives/(true_positives+false_negatives)\n",
    "\n",
    "print('Sensitivity: {:.2f}%'.format(\n",
    "    sensitivity(summary_confusion_matrix)*100\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def specificity(confusion_matrix):\n",
    "    false_positives = confusion_matrix['Predicted Normal']['True Bad']\n",
    "    true_negatives = confusion_matrix['Predicted Bad']['True Bad']\n",
    "    return true_negatives/(true_negatives+false_positives)\n",
    "\n",
    "print('Specificity: {:.2f}%'.format(\n",
    "    specificity(summary_confusion_matrix)*100\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsuprisingly, modelling the traffic as being uniformly distributed with a 50/50 split did not work particularly well. In fact, it gave sensitivity and specificity measures of around $50\\%$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[^1]: rpy2, https://rpy2.bitbucket.io/.\n",
    "\n",
    "[^2]: KDD-CUP-99 Task Description, http://kdd.ics.uci.edu/databases/kddcup99/task.html.\n",
    "\n",
    "[^3]: Hettich, S. and Bay, S. D. (1999). The UCI KDD Archive [http://kdd.ics.uci.edu]. Irvine, CA: University of California, Department of Information and Computer Science.\n",
    "\n",
    "[^4]: Data Science Toolbox: Assignment 1, https://github.com/dj311/data-science-toolbox-1.\n",
    "\n",
    "[^5]: Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
