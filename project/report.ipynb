{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intrusion Detection on the KDD Cup 99 Data Set\n",
    "*An investigation into models and performance metrics for the classification of network data.*\n",
    "\n",
    "--- \n",
    "\n",
    "\n",
    "\n",
    "**TODO** Introduction. Should include:\n",
    "\n",
    "  * Introduce the KDD Cup:\n",
    "    - what was it's aims?\n",
    "    - what does the data set look like? features etc.\n",
    "  * Prior work on the kdd 99 data set\n",
    "    - extensively studied\n",
    "    - papers, code we found, etc.\n",
    "  * Introduce our intended approach, talk about:\n",
    "    - choose a number of approaches to compare\n",
    "    - lots of thought has gone into our performance metric <-- make this clear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib \n",
    "import numpy\n",
    "import pandas\n",
    "import seaborn\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "from statsmodels import api as sm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For inline plots within the notebook\n",
    "%matplotlib inline\n",
    "# Allows code cells to be intrepreted as R (put %%R on the first line) [^1]\n",
    "%load_ext rpy2.ipython\n",
    "# Render R output as HTML\n",
    "from functools import partial\n",
    "from rpy2.ipython import html\n",
    "html.html_rdataframe=partial(html.html_rdataframe, table_class=\"docutils\")\n",
    "html.init_printing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(caret)\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_state = numpy.random.RandomState(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Source\n",
    "\n",
    "Each row in the data represents a single TCP connection, as described in the original task description [2]:\n",
    "> A connection is a sequence of TCP packets starting and ending at some well defined times, between which data flows to and from a source IP address to a target IP address under some well defined protocol.  Each connection is labeled as either normal, or as an attack, with exactly one specific attack type.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `connection_label` column describes the source of each connection; either the name of the red-team which caused the event, or the string `normal.` which indicates normal network behaviour. \n",
    "\n",
    "The task is to create a model which can separate red-team behavour from normal network behaviour, so we need to group the data into two labels: `normal` and `bad`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics for Classification\n",
    "From spec:\n",
    "> - Together agree and test a performance metric.\n",
    ">   - Half of the effort should be devoted to exploring appropriate performance measures.\n",
    ">   - You should create a test and validation dataset, but you may choose how to do this.\n",
    "\n",
    "\n",
    "From spec:\n",
    "> * Think about the circumstances by which your chosen performance metric\n",
    "will lead to real-world generalisability, and how it might compromise this for\n",
    "the purpose of standardization.\n",
    "> * Demonstrate this with data and/or simulation;\n",
    "for example, if you believe that you can predict new types of data, you could\n",
    "demonstrate this by leaving out some types of data and observing your perfor-\n",
    "mance. \n",
    "> * Examine in what sense your groupâ€™s best method is truly best.\n",
    "\n",
    "### Cross-Validation\n",
    "  - Decided on k-fold, why? Brief comparison to other types.\n",
    "\n",
    "### Confusion Matrix\n",
    "\n",
    "### Summary Statistics\n",
    "  - Accurracy\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(confusion_matrix):\n",
    "    true_positives = confusion_matrix[1][1]\n",
    "    true_negative = confusion_matrix[2][2]\n",
    "    false_positives = confusion_matrix[1][2]\n",
    "    false_negative = confusion_matrix[2][1]\n",
    "    return (true_positives +true_negative)/(true_positives+false_positive+true_negatives+false_negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Sensitivity\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sensitivity(confusion_matrix):\n",
    "    true_positives = confusion_matrix[1][1]\n",
    "    false_negatives = confusion_matrix[2][1]\n",
    "    return true_positives/(true_positives+false_negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Specificity\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def specificity(confusion_matrix):\n",
    "    false_positives = confusion_matrix[1][2]\n",
    "    true_negatives = confusion_matrix[2][2]\n",
    "    return true_negatives/(true_negatives+false_positives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Kappa\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Models\n",
    "\n",
    "From spec:\n",
    "> For example, you could look to predict the next event on each\n",
    "edge based on past events on this edge, or you could model the network at a\n",
    "more global level, and many other approaches are possible.\n",
    "\n",
    "**TODO**: We decided to model it on a global scale, why?\n",
    "   - Real-llfe it is hard to keep track of state between events (especially true for high-traffic websites), it's easier to classify each incoming event individually as it goes with a previously trained model.\n",
    "\n",
    "### Logistic Regression\n",
    "\n",
    "### Logistic Regression with Penalisation\n",
    "\n",
    "### SVM\n",
    "\n",
    "## Model Evaluation\n",
    "Here we apply performance metric to models\n",
    "\n",
    "## Evaluation of Performance Metric\n",
    "Here we evaluate how good our performance metric was."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1]: rpy2, https://rpy2.bitbucket.io/.\n",
    "\n",
    "[2]: KDD-CUP-99 Task Description, http://kdd.ics.uci.edu/databases/kddcup99/task.html.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
